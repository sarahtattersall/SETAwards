\subsection{State space exploration}
The state space exploration of a Petri net takes an initial state and performs a breadth-first search to explore the entire state space. We reimplemented a sequential algorithm using object-orientated techniques to improve the readability and re-use of the code and implemented integration tests using the Cucumber framework. An example of these can be seen in \cref{lst:cucumber_state_space}.

\input{modules/integration}

In order to explore Petri nets with large state spaces we reduce the amount of memory used via a dynamic-probabilistic hashing algorithm described in \cite{knottenbelt1996generalised}. This algorithm compresses a state into two numerical values using two separate hash functions. Therefore two states, $s$ and $s'$, are considered equal if and only if $h_1(s) = h_1(s')$ and $h_2(s) = h_2(s')$.

In order to parallelise this process we developed a thread based algorithm that takes inspiration from Hadoop and is in the form of a MapReduce problem. In order to process states in parallel the main thread starts up a specified number of worker threads, normally one for each virtual core. Once running each thread performs the sequential breadth first algorithm, keeping track of the state transitions which it has processed. 
% In order to try and avoid threads processing a state more than once we make use of a concurrent non-blocking shared queue.
We allow each worker thread to run until it has processed a specified number of states or the exploration queue is empty after which it returns with the data it has collected. The main algorithm then collects the results as threads finish, writes them to disk, stores the explored states in a custom written compressed state data structure and starts another iteration off. This continues until the state space has been fully explored.

In order to improve performance of the state space exploration algorithm the code was profiled using the YourKit Java profiler which led to some interesting changes being made. Since we made use of temporary caches in the algorithm one interesting change involved pre-computing a states two hash codes on creation so that when determining equality of states and membership in our custom written data set we need only check two numerical values rather than the entire states themselves. 