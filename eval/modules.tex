\subsection{Analysing the new modules}
Our new sequential state space exploration algorithm  yields increasing speedups compared to PIPE 4 for small state spaces as can be seen in \cref{tbl:pipe5_vs_pipe4_sequential}. Interestingly the algorithm for the sequential exploration does not differ from that of PIPE 4, the speedup comes from advanced data structure usage, memoization and other optimisation techniques.

\begin{table}[tb]
\begin{center}
  \begin{tabular}{| c | c | c | c | c | }
  \hline
    Number of states & Number of transitions & PIPE 4 (s) & PIPE 5 (s) & Speedup \\
    \hline
    40 & 156 & 0.21 & 0.17 & 1.24\\
    \hline
    100 & 480 & 0.36 & 0.40 & 0.90\\
    \hline
    625 & 4000 & 25.12 & 1.35 & 18.61\\
    \hline
    1350 & 9450 & 83.67 & 1.75 & 47.81\\
    \hline
    4096 & 28672 & 728.02 & 3.82 & 190.58\\
    \hline
    11664 & 93312 & 2738.37 & 8.51 & 321.78\\
    \hline
  \end{tabular}
\caption{The time taken in seconds to generate the reachability graph in PIPE 4 compared with the new sequential algorithm in PIPE 5. For very small state spaces we can see that the times are comparable, but for moderate sized Petri nets PIPE 5 is more scalable.}
\label{tbl:pipe5_vs_pipe4_sequential}
\end{center}
\end{table}

% Next we compare our sequential algorithm to our MapReduce-style parallel algorithm running on 4 virtual cores. Since the underlying algorithm performed  is very similar we expect to see a linear speedup and indeed the results in \cref{fig:parallel_vs_sequential_algo} show approximately this. We allowed each worker thread to process 100, 200, 500 states before returning to have their results reduced and although there is little difference between them, the 100 states per thread run provides the best speedup against the sequential implementation. Using these results we went on to investigate the benefits for larger state spaces and observed that we see similar speedups in \cref{fig:pipe5_large_state_space}.

% \input{eval/state_space.tex}
% \input{eval/large_state_space.tex}

% Overall these results show a considerate speedup and allow for Petri nets with large state spaces to be analysed realistically on local machines.

To investigate the scalability of our parallel algorithm we analyse the new sequential and parallel algorithms against each other using a machine with a 3.40Ghz quad-core i7 processor. \cref{fig:scalability} shows that whilst the speedup from 2 to 4 virtual cores is promising at around 60\%, we do not get such good results from running the algorithm with 8 virtual cores. On profiling we found that the bottleneck in our algorithm is the creation of a states primary and secondary hash codes, taking 68\% of the algorithms run-time. Unfortunately since there is no implementation of a concurrent queue in Java that does not allow duplicates, we discovered that quite often it is possible to add a state twice to the exploration queue, meaning that its successors get generated twice too, causing their hash codes to be re-calculated.

\input{eval/labs_state_space.tex}

Nevertheless in order to put into perspective the speedup gained by our new parallel algorithm using 100 states per thread and 8 virtual-cores we compared the run-times of a 4096 state Petri net with this algorithm and PIPE 4. Whilst PIPE 4 explores the state space in 9.37 minutes, our new algorithm can explore it in 2.65 seconds which amounts to an incredible 211x speedup. Moreover our new algorithm can solve a Petri net with \num{1099999} states in 5.77 minutes which is faster than the time taken to solve the 4096 state Petri net in PIPE 4!